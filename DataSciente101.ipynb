{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Science 101\n",
    "\n",
    "## Qué es Data Science?\n",
    "\n",
    "La ciencia de datos es un campo interdisciplinario que utiliza métodos, procesos, algoritmos y sistemas científicos para extraer conocimiento y comprensión de datos en diversas formas, tanto estructurados como no estructurados. Es un campo que combina estadísticas, análisis de datos y aprendizaje automático para interpretar y analizar grandes volúmenes de in"
   ],
   "id": "e326feb0fbef9132"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Qué necesitamos para hacer Data Science?\n",
    "- Datos: Información que se puede analizar. procesar y extraer conocimiento de ellos.\n",
    "- Herramientas: Software y lenguajes de programación que facilitan el análisis de datos.\n",
    "- Conocimientos: Entender los conceptos básicos de estadística, programación y análisis de datos."
   ],
   "id": "f6a68b5565fc3497"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Herramientas y Lenguajes de Programación\n",
    "- **Python**: Un lenguaje de programación versátil y fácil de aprender, ampliamente utilizado en ciencia de datos.\n",
    "- **R**: Un lenguaje especializado en análisis estadístico y visualización de datos.\n",
    "- **SQL**: Un lenguaje de consulta para bases de datos relacionales, esencial para manipular y extraer datos.\n",
    "- **Jupyter Notebooks**: Un entorno interactivo para escribir y ejecutar código, ideal para análisis exploratorio de datos.\n",
    "- **Pandas**: Una biblioteca de Python para manipulación y análisis de datos, que proporciona estructuras de datos flexibles y eficientes.\n",
    "- **NumPy**: Una biblioteca de Python para cálculos numéricos, que proporciona soporte para arreglos multidimensionales y funciones matemáticas.\n",
    "- **Matplotlib y Seaborn**: Bibliotecas de visualización de datos en Python, que permiten crear gráficos y visualizaciones atractivas.\n",
    "- **Scikit-learn**: Una biblioteca de Python para aprendizaje automático, que proporciona herramientas para construir y evaluar modelos predictivos.\n",
    "- **PyTorch**: Biblioteca de Python para aprendizaje profundo, que permiten construir y entrenar redes neuronales complejas."
   ],
   "id": "addf25f999e45d08"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-10T01:25:01.063167Z",
     "start_time": "2025-06-10T01:25:01.057740Z"
    }
   },
   "source": [
    "import cudf # Para trabajar con GPU\n",
    "import pandas as pd # Para trabajar con CPU\n",
    "import numpy as np # Para trabajar con arreglos y matrices\n",
    "import matplotlib.pyplot as plt # Para visualización de datos\n",
    "import seaborn as sns # Para visualización de datos\n",
    "import pygwalker as pyg # Para visualización interactiva de datos"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Introducción a Pandas\n",
    "\n",
    "Pandas es una biblioteca de Python que proporciona estructuras de datos y herramientas de análisis de datos. Es especialmente útil para manipular y analizar datos tabulares, como hojas de cálculo o bases de datos, y es ampliamente utilizada en ciencia de datos.\n"
   ],
   "id": "487db6cbabc9bba8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Estructuras de Datos en Pandas\n",
    "- **Series**: Una estructura unidimensional similar a una lista o un arreglo, que puede contener cualquier tipo de datos y tiene etiquetas (índices).\n",
    "- **DataFrame**: Una estructura bidimensional similar a una tabla, que contiene filas y columnas, donde cada columna puede tener un tipo de dato diferente. Es la estructura de datos más utilizada en Pandas.\n",
    "- **Panel**: Una estructura tridimensional, menos utilizada, que puede ser vista como una colección de DataFrames. Sin embargo, en la práctica, los DataFrames son suficientes para la mayoría de las tareas de análisis de datos.\n",
    "- **Categorías**: Una estructura que permite trabajar con datos categóricos, optimizando el uso de memoria y mejorando el rendimiento en ciertas operaciones.\n",
    "- **Time Series**: Una estructura especializada para trabajar con datos temporales, que permite realizar operaciones específicas como resampling y rolling windows.\n",
    "- **Sparse DataFrames**: Una estructura que permite trabajar con datos dispersos, donde la mayoría de los valores son nulos o cero, optimizando el uso de memoria.\n",
    "- **MultiIndex**: Una estructura que permite trabajar con índices jerárquicos, facilitando el manejo de datos con múltiples niveles de agrupación."
   ],
   "id": "4f39f8d2e04156d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src = \"imagenes/img.png\" width = \"800\">",
   "id": "2cfb6738fc7ca6f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conceptos Básicos de Pandas\n",
    "- **Instalación**: Pandas se puede instalar utilizando pip o conda. Por ejemplo, `pip install pandas`.\n",
    "- **Importación**: Para utilizar Pandas en un script de Python, se debe importar la biblioteca con `import pandas `\n",
    "- **Creación de Series y DataFrames**:\n",
    "  - Una Serie se puede crear a partir de una lista, un diccionario o un arreglo de NumPy.\n",
    "  - Un DataFrame se puede crear a partir de un diccionario de listas, un diccionario de Series, una lista de diccionarios o un archivo."
   ],
   "id": "1c1d541b44945e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T01:42:01.223586Z",
     "start_time": "2025-06-10T01:42:01.208530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creacion de una Serie\n",
    "serie = pd.Series([1, 2, 3, 4, 5])\n",
    "# Creacion de un DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'columna1': [1, 2, 3],\n",
    "    'columna2': ['a', 'b', 'c'],\n",
    "    'columna3': [True, False, True]\n",
    "})"
   ],
   "id": "792e93c2c02eee0b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T01:42:02.759636Z",
     "start_time": "2025-06-10T01:42:02.752086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mostrar la Serie y el DataFrame\n",
    "print(\"Serie:\")\n",
    "print(serie)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(data)"
   ],
   "id": "77656d0d90a4b16d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie:\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "\n",
      "DataFrame:\n",
      "   columna1 columna2  columna3\n",
      "0         1        a      True\n",
      "1         2        b     False\n",
      "2         3        c      True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Acceso a Datos en Pandas\n",
    "\n",
    "De nada nos sirve tener datos si no podemos acceder a ellos. Pandas proporciona varias formas de acceder a los datos en Series y DataFrames.\n",
    "\n",
    "- Slicing: Permite acceder a un subconjunto de datos utilizando índices o etiquetas `data[0:2]` o `data['columna1']`.\n",
    "- Indexación: Permite acceder a datos específicos utilizando etiquetas o posiciones. Por ejemplo, `data.iloc[0]` para acceder a la primera fila o `data['columna1']` para acceder a una columna específica.\n",
    "- Filtrado: Permite seleccionar filas que cumplen ciertas condiciones. Por ejemplo, `data[data['columna1'] > 1]` para seleccionar filas donde el valor de 'columna1' es mayor que 1.\n",
    "- Métodos de acceso: Pandas proporciona métodos como `head()`, `tail()`, `loc[]` e `iloc[]` para acceder a datos de manera más flexible.\n",
    "    - head(): Muestra las primeras n filas del DataFrame (por defecto 5).\n",
    "    - tail(): Muestra las últimas n filas del DataFrame (por defecto 5).\n",
    "    - loc[]: Permite acceder a filas y columnas por etiquetas.\n",
    "    - iloc[]: Permite acceder a filas y columnas por posición entera.\n"
   ],
   "id": "d4976aa9daf70830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T01:51:25.764603Z",
     "start_time": "2025-06-10T01:51:25.752044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Slicing\n",
    "sliced_data = data[0:2]  # Accede a las primeras 2 filas\n",
    "# Indexación\n",
    "indexed_data = data.iloc[0]  # Accede a la primera fila\n",
    "# Filtrado\n",
    "filtered_data = data[data['columna1'] > 1]  # Filtra filas donde 'columna1' es mayor que 1\n",
    "# Métodos de acceso\n",
    "print(\"Head:\")\n",
    "print(data.head())# Muestra las primeras 5 filas\n",
    "print(\"Tail:\")\n",
    "print(data.tail())  # Muestra las últimas 5 filas"
   ],
   "id": "98316a902c045ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "   columna1 columna2  columna3\n",
      "0         1        a      True\n",
      "1         2        b     False\n",
      "2         3        c      True\n",
      "Tail:\n",
      "   columna1 columna2  columna3\n",
      "0         1        a      True\n",
      "1         2        b     False\n",
      "2         3        c      True\n",
      "Loc:\n",
      "columna1       1\n",
      "columna2       a\n",
      "columna3    True\n",
      "Name: 0, dtype: object\n",
      "Iloc:\n",
      "columna1       1\n",
      "columna2       a\n",
      "columna3    True\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cargando Datos en Pandas\n",
    "Pandas permite cargar datos desde diferentes fuentes, como archivos CSV, Excel, bases de datos SQL y más. Los métodos más comunes para cargar datos son:\n",
    "- `read_csv()`: Carga datos desde un archivo CSV.\n",
    "- `read_excel()`: Carga datos desde un archivo Excel.\n",
    "- `read_sql()`: Carga datos desde una base de datos SQL.\n",
    "- `read_json()`: Carga datos desde un archivo JSON.\n",
    "- `read_html()`: Carga datos desde una tabla HTML.\n",
    "- `read_parquet()`: Carga datos desde un archivo Parquet, un formato de almacenamiento columnar eficiente.\n",
    "- `read_feather()`: Carga datos desde un archivo Feather, un formato de almacenamiento binario eficiente para DataFrames.\n",
    "- `read_pickle()`: Carga datos desde un archivo pickle, que permite serializar objetos de Python.\n",
    "- `read_clipboard()`: Carga datos desde el portapapeles, útil para copiar y pegar datos tabulares desde otras aplicaciones."
   ],
   "id": "8b2c90622d7bda36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T01:53:58.516058Z",
     "start_time": "2025-06-10T01:53:58.385271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargando datos desde un archivo CSV\n",
    "data_csv = pd.read_csv('Melbourne_housing_FULL.csv')  # Reemplaza 'ruta/al/archivo.csv' con la ruta real del archivo\n",
    "data_csv"
   ],
   "id": "51d25e6694fe84c2",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Melbourne_housing_FULL.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Cargando datos desde un archivo CSV\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m data_csv = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mMelbourne_housing_FULL.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Reemplaza 'ruta/al/archivo.csv' con la ruta real del archivo\u001B[39;00m\n\u001B[32m      3\u001B[39m data_csv\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/AI/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/AI/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/AI/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/AI/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/AI/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'Melbourne_housing_FULL.csv'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "caf42c0743a047a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
